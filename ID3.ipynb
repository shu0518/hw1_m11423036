{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f91a8212-8014-4454-8f21-3998ce36fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "處理訓練資料...\n",
      "==================================================\n",
      "移除 24 筆重複資料\n",
      "欄位 workclass 有缺失值，使用眾數 'Private' 填補\n",
      "欄位 occupation 有缺失值，使用眾數 'Prof-specialty' 填補\n",
      "欄位 native-country 有缺失值，使用眾數 'United-States' 填補\n",
      "開始離散化數值特徵...\n",
      "訓練資料筆數: 32537\n",
      "\n",
      "==================================================\n",
      "處理測試資料...\n",
      "==================================================\n",
      "移除 5 筆重複資料\n",
      "欄位 workclass 有缺失值，使用眾數 'Private' 填補\n",
      "欄位 occupation 有缺失值，使用眾數 'Prof-specialty' 填補\n",
      "欄位 native-country 有缺失值，使用眾數 'United-States' 填補\n",
      "開始離散化數值特徵...\n",
      "測試資料筆數: 16276\n",
      "\n",
      "開始訓練 ID3 決策樹模型...\n",
      "訓練完成。\n",
      "\n",
      "==================================================\n",
      "                訓練資料性能指標                \n",
      "==================================================\n",
      "  準確率 (Accuracy) : 83.59%\n",
      "  精確度 (Precision): 69.49%\n",
      "  召回率 (Recall)   : 56.83%\n",
      "  F1-Score        : 62.53%\n",
      "            \n",
      "--- Confusion Matrix ---             \n",
      "  真陽性 (True Positive, TP)    : 4455      \n",
      "  真陰性 (True Negative, TN)    : 22742     \n",
      "  偽陽性 (False Positive, FP)   : 1956      \n",
      "  偽陰性 (False Negative, FN)   : 3384      \n",
      "\n",
      "==================================================\n",
      "                測試資料性能指標                \n",
      "==================================================\n",
      "  準確率 (Accuracy) : 83.03%\n",
      "  精確度 (Precision): 67.24%\n",
      "  召回率 (Recall)   : 54.97%\n",
      "  F1-Score        : 60.49%\n",
      "            \n",
      "--- Confusion Matrix ---             \n",
      "  真陽性 (True Positive, TP)    : 2114      \n",
      "  真陰性 (True Negative, TN)    : 11400     \n",
      "  偽陽性 (False Positive, FP)   : 1030      \n",
      "  偽陰性 (False Negative, FN)   : 1732      \n",
      "\n",
      "預測結果已匯出至: adult_predictions_ID3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 1. 讀入套件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 用於輸出 Excel 檔案\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# 2. 資料預處理\n",
    "class ID3DataPreprocessor:\n",
    "    def __init__(self, train_path: str, test_path: str, bins: int = 5):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.bins = bins\n",
    "        self.column_names = [\n",
    "            'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "            'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "            'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
    "        ]\n",
    "        self.original_categorical_features = [\n",
    "            'workclass', 'education', 'marital-status', 'occupation',\n",
    "            'relationship', 'race', 'sex', 'native-country'\n",
    "        ]\n",
    "        self.original_numerical_features = [\n",
    "            'age', 'fnlwgt', 'education-num', 'capital-gain',\n",
    "            'capital-loss', 'hours-per-week'\n",
    "        ]\n",
    "        self.bin_edges = {}\n",
    "\n",
    "    def discretize_numerical_features(self, df: pd.DataFrame, is_train: bool) -> pd.DataFrame:\n",
    "        for col in self.original_numerical_features:\n",
    "            if is_train:\n",
    "                df[col], bins = pd.qcut(df[col], q=self.bins, retbins=True, duplicates='drop')\n",
    "                self.bin_edges[col] = bins\n",
    "            else:\n",
    "                bins = self.bin_edges[col]\n",
    "                robust_bins = np.copy(bins)\n",
    "                robust_bins[0], robust_bins[-1] = -np.inf, np.inf\n",
    "                df[col] = pd.cut(df[col], bins=robust_bins, include_lowest=True)\n",
    "            df[col] = df[col].astype(str)\n",
    "        return df\n",
    "\n",
    "    def load_and_preprocess(self, filepath: str, is_train: bool = False) -> pd.DataFrame:\n",
    "        skip = 1 if not is_train else 0\n",
    "        df = pd.read_csv(filepath, names=self.column_names, \n",
    "                         skipinitialspace=True, na_values='?', skiprows=skip)\n",
    "        if not is_train:\n",
    "            df['income'] = df['income'].str.rstrip('.')\n",
    "        \n",
    "        initial_rows = len(df)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        if initial_rows > len(df):\n",
    "            print(f\"移除 {initial_rows - len(df)} 筆重複資料\")\n",
    "        \n",
    "        for col in self.original_categorical_features + self.original_numerical_features:\n",
    "            if df[col].isnull().any():\n",
    "                if col in self.original_categorical_features:\n",
    "                    fill_value = df[col].mode()[0]\n",
    "                    print(f\"欄位 {col} 有缺失值，使用眾數 '{fill_value}' 填補\")\n",
    "                else:\n",
    "                    fill_value = df[col].median()\n",
    "                    print(f\"欄位 {col} 有缺失值，使用中位數 {fill_value} 填補\")\n",
    "                df[col].fillna(fill_value, inplace=True)\n",
    "\n",
    "        print(\"開始離散化數值特徵...\")\n",
    "        df = self.discretize_numerical_features(df, is_train)\n",
    "        \n",
    "        df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "        df.dropna(subset=['income'], inplace=True)\n",
    "        df['income'] = df['income'].astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def run(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        print(\"=\" * 50 + \"\\n處理訓練資料...\\n\" + \"=\" * 50)\n",
    "        train_df = self.load_and_preprocess(self.train_path, is_train=True)\n",
    "        print(f\"訓練資料筆數: {len(train_df)}\\n\")\n",
    "        \n",
    "        print(\"=\" * 50 + \"\\n處理測試資料...\\n\" + \"=\" * 50)\n",
    "        test_df = self.load_and_preprocess(self.test_path, is_train=False)\n",
    "        print(f\"測試資料筆數: {len(test_df)}\")\n",
    "        return train_df, test_df\n",
    "\n",
    "# 3. ID3 決策樹實作 \n",
    "class ID3Node:\n",
    "    def __init__(self):\n",
    "        self.feature: Optional[str] = None\n",
    "        self.is_leaf: bool = False\n",
    "        self.prediction: Optional[int] = None\n",
    "        self.children: Dict = {}\n",
    "        self.class_distribution: Dict = {}\n",
    "\n",
    "class ID3DecisionTree:\n",
    "    def __init__(self, max_depth: Optional[int] = None, min_samples_split: int = 2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root: Optional[ID3Node] = None\n",
    "\n",
    "    def _entropy(self, y: np.ndarray) -> float:\n",
    "        if len(y) == 0: return 0.0\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "    def _information_gain(self, X_col: pd.Series, y: np.ndarray) -> float:\n",
    "        parent_entropy = self._entropy(y)\n",
    "        child_entropy = sum((len(subset_y) / len(y)) * self._entropy(subset_y) \n",
    "                            for _, subset_y in y.groupby(X_col))\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    def _best_split(self, X: pd.DataFrame, y: pd.Series) -> Optional[str]:\n",
    "        gains = {feature: self._information_gain(X[feature], y) for feature in X.columns}\n",
    "        best_feature = max(gains, key=gains.get)\n",
    "        return best_feature if gains[best_feature] > 0 else None\n",
    "\n",
    "    def _build_tree(self, X: pd.DataFrame, y: pd.Series, depth: int) -> ID3Node:\n",
    "        node = ID3Node()\n",
    "        node.class_distribution = y.value_counts().to_dict()\n",
    "        most_common_class = y.mode()[0]\n",
    "\n",
    "        stop_splitting = (\n",
    "            len(y.unique()) == 1 or\n",
    "            len(y) < self.min_samples_split or\n",
    "            (self.max_depth is not None and depth >= self.max_depth)\n",
    "        )\n",
    "        if stop_splitting:\n",
    "            node.is_leaf = True\n",
    "            node.prediction = most_common_class\n",
    "            return node\n",
    "\n",
    "        best_feature = self._best_split(X, y)\n",
    "        if not best_feature:\n",
    "            node.is_leaf = True\n",
    "            node.prediction = most_common_class\n",
    "            return node\n",
    "        \n",
    "        node.feature = best_feature\n",
    "        for value, group in X.groupby(best_feature):\n",
    "            node.children[value] = self._build_tree(group.drop(columns=[best_feature]), y.loc[group.index], depth + 1)\n",
    "        return node\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        print(\"\\n開始訓練 ID3 決策樹模型...\")\n",
    "        y_series = pd.Series(y, index=X.index) # 確保 y 也是 Series\n",
    "        self.root = self._build_tree(X, y_series, 0)\n",
    "        print(\"訓練完成。\")\n",
    "    \n",
    "    def _predict_sample(self, x: pd.Series, node: ID3Node) -> int:\n",
    "        if node.is_leaf:\n",
    "            return node.prediction\n",
    "        \n",
    "        feature_value = x.get(node.feature)\n",
    "        if feature_value not in node.children:\n",
    "            return max(node.class_distribution, key=node.class_distribution.get)\n",
    "        \n",
    "        return self._predict_sample(x, node.children[feature_value])\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        if self.root is None: raise ValueError(\"模型尚未訓練\")\n",
    "        return X.apply(self._predict_sample, axis=1, node=self.root).to_numpy()\n",
    "\n",
    "# 4. 主程式與評估模型\n",
    "def print_metrics(y_true: np.ndarray, y_pred: np.ndarray, title: str):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50 + f\"\\n{title.center(40)}\\n\" + \"=\" * 50)\n",
    "    print(f\"  準確率 (Accuracy) : {accuracy:.2%}\")\n",
    "    print(f\"  精確度 (Precision): {precision:.2%}\")\n",
    "    print(f\"  召回率 (Recall)   : {recall:.2%}\")\n",
    "    print(f\"  F1-Score        : {f1:.2%}\")\n",
    "    print(\"\\n--- Confusion Matrix ---\".center(50))\n",
    "    print(f\"  {'真陽性 (True Positive, TP)':<25}  : {tp:<10}\")\n",
    "    print(f\"  {'真陰性 (True Negative, TN)':<25}  : {tn:<10}\")\n",
    "    print(f\"  {'偽陽性 (False Positive, FP)':<25}  : {fp:<10}\")\n",
    "    print(f\"  {'偽陰性 (False Negative, FN)':<25}  : {fn:<10}\")\n",
    "    \n",
    "def export_to_excel(y_true: np.ndarray, y_pred: np.ndarray, filename: str):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Prediction Results\"\n",
    "    ws.append(['實際類別', '預測類別'])\n",
    "    \n",
    "    label_map = {0: '<=50K', 1: '>50K'}\n",
    "    for true_val, pred_val in zip(y_true, y_pred):\n",
    "        ws.append([label_map[true_val], label_map[pred_val]])\n",
    "        \n",
    "    wb.save(filename)\n",
    "    print(f\"\\n預測結果已匯出至: {filename}\")\n",
    "\n",
    "# 主程式 \n",
    "def main():\n",
    "    # --- 在此處手動調整參數 ---\n",
    "    BINS = 10  #數值特徵離散化的區間數\n",
    "    MAX_DEPTH = 8\n",
    "    MIN_SAMPLES_SPLIT = 200 #節點可被分割的最小樣本數\n",
    "    # --------------------------\n",
    "    \n",
    "    # 執行資料預處理\n",
    "    preprocessor = ID3DataPreprocessor('adult/adult.data', 'adult/adult.test', bins=BINS)\n",
    "    train_df, test_df = preprocessor.run()\n",
    "    \n",
    "    # 分離特徵 (X) 與目標 (y)\n",
    "    X_train = train_df.drop('income', axis=1)\n",
    "    y_train = train_df['income'].values\n",
    "    X_test = test_df.drop('income', axis=1)\n",
    "    y_test = test_df['income'].values\n",
    "    \n",
    "    # 建立與訓練模型\n",
    "    model = ID3DecisionTree(max_depth=MAX_DEPTH, min_samples_split=MIN_SAMPLES_SPLIT)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 預測與評估\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print_metrics(y_train, y_pred_train, \"訓練資料性能指標\")\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print_metrics(y_test, y_pred_test, \"測試資料性能指標\")\n",
    "    \n",
    "    # 匯出結果\n",
    "    export_to_excel(y_test, y_pred_test, 'adult_predictions_ID3.xlsx')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9542cc8-8924-46ec-8da2-73d496e13278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
